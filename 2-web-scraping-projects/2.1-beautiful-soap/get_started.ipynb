{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Web Scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_url = \"https://raw.githubusercontent.com/PedroFerreiraBento/Python-Projects/main/2-web-scraping-projects/2.1-beautiful-soap\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Simple request\n",
    "Request data from an url and output the HTML file received on response.\n",
    "\n",
    "Note: Here we are requesting the raw data of a HTML file that is present in this project, but the github file is on the Web and that is where we are making the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "html = urlopen(f\"{project_url}/static/example-1.html\")\n",
    "print(html.read())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - BeautifulSoup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install beautifulsoup4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Parse HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen(f\"{project_url}/static/example-1.html\")\n",
    "bs = BeautifulSoup(html.read(), \"html.parser\")\n",
    "\n",
    "print(f\"First instance of 'p' tag found: {bs.p.string}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Trying other parsers\n",
    "\n",
    "You can check the other parsers and them difference here: [**Difference between parsers**](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#differences-between-parsers)\n",
    "\n",
    "Some parser will need to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lxml\n",
    "%pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_parser = BeautifulSoup(\"<a></b></a>\", \"html.parser\")\n",
    "lxml = BeautifulSoup(\"<a></b></a>\", \"lxml\")\n",
    "html_lib = BeautifulSoup(\"<a></b></a>\", \"html5lib\")\n",
    "\n",
    "print(f\"'html.parser' parser: {html_parser}\")\n",
    "print(f\"'lxml' parser: {lxml}\")\n",
    "print(f\"'html5lib' parser: {html_lib}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Handling exceptions\n",
    "\n",
    "Two main things can go wrong in the request:\n",
    "- The page is not found on the server (or there was an error in retrieving it).\n",
    "- The server is not found."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 - Page not found\n",
    "\n",
    "Raises HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "try:\n",
    "    html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "except HTTPError as e:\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 - Server not found\n",
    "\n",
    "Raises URLError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen('https://pythonscrapingthisurldoesnotexist.com')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "except URLError as e:\n",
    "    print('The server could not be found!')\n",
    "else:\n",
    "    print('It Worked!')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.3 - Tag not found\n",
    "\n",
    "If you try to access a tag that does not exist in the file the BeautifulSoup will return None. But if you try to access an element inside a non-existing tag it will raise an AttributeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen(f\"{project_url}/static/example-1.html\")\n",
    "bs = BeautifulSoup(html.read(), \"html.parser\")\n",
    "\n",
    "# Return None\n",
    "print(f\"Non-existing tag: { bs.missingtag }\")\n",
    "\n",
    "# Raise AttributeError\n",
    "try: \n",
    "    print(bs.missingtag.a)\n",
    "except AttributeError:\n",
    "    print(\"Tag not found!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Filter page\n",
    "\n",
    "BeautifulSoup has two methods to filter HTML pages:\n",
    "\n",
    "- **find()** - To get the first match\n",
    "- **find_all()** - To get all matches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.1 - Count elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen(f\"{project_url}/static/example-2.html\")\n",
    "bs = BeautifulSoup(html.read(), \"html.parser\")\n",
    "\n",
    "print(f\"Count rows: {len(bs.find_all(['tr', 'td']))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.2 - Tag and attributes filter\n",
    "\n",
    "It's like an **or** filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bs.find(\"table\", {\"id\": \"ageTable\"}))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.3 - Keyword filter \n",
    "\n",
    "It's like an **and** filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bs.find(id=\"ageTable\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.4 - Content filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 35 age: 1\n"
     ]
    }
   ],
   "source": [
    "count = len(bs.find_all(string=\"35\"))\n",
    "print(f\"Count 35 age: {count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 - Navigation trees\n",
    "\n",
    "Find tags based on document location\n",
    "\n",
    "#### 2.6.1 - Children and Descendants\n",
    "\n",
    "Children are always one tag below their parents.\n",
    "Descendants can be at any level below the parents.\n",
    "\n",
    "All children are descendants, but not all descendants are children. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Children count: 9\n",
      "Descendants count: 37\n"
     ]
    }
   ],
   "source": [
    "children = bs.find(id=\"ageTable\").children\n",
    "descendants = bs.find(id=\"ageTable\").descendants\n",
    "\n",
    "print(f\"Children count: {len(list(children))}\")\n",
    "print(f\"Descendants count: {len(list(descendants))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6.2 - Siblings\n",
    "\n",
    "Siblings are tags in the same tree level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object PageElement.next_siblings at 0x000001E8192FFE80>\n",
      "Row 0: \n",
      "\n",
      "\n",
      "Row 1: \n",
      "<tr>\n",
      "<td>John</td>\n",
      "<td>35</td>\n",
      "</tr>\n",
      "Row 2: \n",
      "\n",
      "\n",
      "Row 3: \n",
      "<tr>\n",
      "<td>Jeffrey</td>\n",
      "<td>40</td>\n",
      "</tr>\n",
      "Row 4: \n",
      "\n",
      "\n",
      "Row 5: \n",
      "<tr>\n",
      "<td>Jorge</td>\n",
      "<td>21</td>\n",
      "</tr>\n",
      "Row 6: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_row = bs.find(\"table\", {\"id\": \"ageTable\"}).tr\n",
    "\n",
    "print(first_row.next_sibling)\n",
    "\n",
    "for index, row in enumerate(first_row.next_siblings):\n",
    "    print(f\"Row {index}: \\n{row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
